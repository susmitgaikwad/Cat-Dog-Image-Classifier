{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Part 1 - Building the CNN\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "import argparse\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.preprocessing import image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolution and Pooling are both matrix operations using arithmetic on the image pixel values which we convert into matrices formats. \n",
    "\n",
    "**Convolution** is done for feature extraction by using a filter matrix (n x n) which is basically a smaller matrix (n < m) than the image matrix (m x m). We do multiplication and addition by 'striding' the filter matrix over the image matrix (covers n x n of input matrix at a time) and get a single value for each stride. Effectively the new matrix is a much smaller one.\n",
    "\n",
    "**Pooling** is done to reduce the dimensionality but also make sure no information is lost. Similar to the filter, a pooling matirx strides over input matrix and selects the value that satisfies it's pooling condition. For eg: we are using max pooling. Thus for every stride, it chooses the max value from the current n x n matrix in it's stride.\n",
    "\n",
    "Rectified Linear Unit is an activation function takes the output value of X and compares it to find the max(0,X). If X > 0 then it returns X, else of X < 0 it returns 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution operation using a filter (no of filter,(shape of filter)),(res x res, 3 stands for RGB)\n",
    "model.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "\n",
    "# Pooling -> to reduce matrix by selecting max image\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "\n",
    "# Flattening -> converts 2D arrays into vectors\n",
    "model.add(Flatten())\n",
    "\n",
    "# Dense layer for fully connected layer\n",
    "model.add(Dense(units = 128, activation = 'relu'))\n",
    "model.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimizer makes sure we reach the local or global minima to ensure lowest value of the cost function. THe loss function calculates the difference between predicted and target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compiling the CNN\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use an image generator for the purpose of **Image Augmentation**. This is the process of taking images that are in our training dataset and manipulating them to create many altered versions of the same image. This both provides more images to train on, but can also help expose the classifier to a wider range of lighting, coloring situations as well as aspect ratio change or angle change so as to make the classifier more robust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2,horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_set = datagen.flow_from_directory('dataset/training_set', target_size = (64, 64), \n",
    "                                           batch_size = 32, class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_set = datagen.flow_from_directory('dataset/test_set', target_size = (64, 64), batch_size = 32, class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch size is the number of data samples the network works on at once. As far as I understand, this does not improve accuracy but speed instead. Default value is 32 but you can change that acc to your PC specs I guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(training_set, steps_per_epoch = 4000, epochs = 10, validation_data = test_set, validation_steps = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An epoch is one whole iteration over the training dataset i.e. the network has seen all the training data once after one epoch and so forth. Steps per epoch is the number of steps (how many batches of data samples) to fetch from generator before declaring one epoch finished and starting the next epoch. This number of steps should typically be equal to the number of samples (8000) of your dataset divided by the batch size (32) but for some reason 4000 worked nice for me by trial and error. Go figure  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_image = image.load_img('dataset/moonmoon.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = model.predict(test_image)\n",
    "print(result)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'dog'\n",
    "    print(prediction)\n",
    "else:\n",
    "    prediction = 'cat'\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code is for saving your model once you achieve your desired accuracy. Sequently it can be loaded as shown in the cells further down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X, Y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.]]\n"
     ]
    }
   ],
   "source": [
    "test_image = image.load_img('dataset/catssuck.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "\n",
    "result = loaded_model.predict(test_image)\n",
    "print(result)\n",
    "# training_set.class_indices\n",
    "# if result[0][0] == 1:\n",
    "#     prediction = 'dog'\n",
    "#     print(prediction)\n",
    "# else:\n",
    "#     prediction = 'cat'\n",
    "#     print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
